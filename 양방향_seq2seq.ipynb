{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Dyfhm_YkCNwt31hoA2nJtdU1CgWE3llF","authorship_tag":"ABX9TyNB56hl+1Pj1xilgCup6vU6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"84a2c1e08a4944b7a7359b14a2c49378":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7232354dd62144d882cef70165a8fca6","IPY_MODEL_883a29f7dc8349b7b5d82c3f8d263f0f","IPY_MODEL_0b4ff8cad8694b169a780b5174a0bcbe"],"layout":"IPY_MODEL_979a3f26c23542f9af5fe2b598cacb0e"}},"7232354dd62144d882cef70165a8fca6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c17ebd05cf7493b9ba03b0fb485cb8e","placeholder":"​","style":"IPY_MODEL_f61a24437a3a40dfb6cedec962fdb225","value":" 80%"}},"883a29f7dc8349b7b5d82c3f8d263f0f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc1978e415c64555a8238a2f57f9b5bf","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66d1113ff9c7463c9e43710fe3c8aa13","value":40000}},"0b4ff8cad8694b169a780b5174a0bcbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fea253f4f71464e8c639083a007d137","placeholder":"​","style":"IPY_MODEL_e1e76ab156eb409dac6c3509cec7f10d","value":" 40000/50000 [2:23:31&lt;26:55,  6.19it/s]"}},"979a3f26c23542f9af5fe2b598cacb0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c17ebd05cf7493b9ba03b0fb485cb8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f61a24437a3a40dfb6cedec962fdb225":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc1978e415c64555a8238a2f57f9b5bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66d1113ff9c7463c9e43710fe3c8aa13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fea253f4f71464e8c639083a007d137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e76ab156eb409dac6c3509cec7f10d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xjiYXQdz8AkA","executionInfo":{"status":"ok","timestamp":1720284378629,"user_tz":-540,"elapsed":8474,"user":{"displayName":"유인","userId":"09840046609030674956"}},"outputId":"eaf7265e-139a-4368-ca5b-a5ca7be99ca0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"]}]},{"cell_type":"code","source":["!pip install torch transformers tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X559zSti8Jgo","executionInfo":{"status":"ok","timestamp":1720284460732,"user_tz":-540,"elapsed":70077,"user":{"displayName":"유인","userId":"09840046609030674956"}},"outputId":"d1ad5da4-55be-4596-c719-d8f94f1cae71"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"E7HAG9EX61FB","executionInfo":{"status":"ok","timestamp":1720284463165,"user_tz":-540,"elapsed":7,"user":{"displayName":"유인","userId":"09840046609030674956"}}},"outputs":[],"source":["import math\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from konlpy.tag import Okt\n","from tqdm.auto import tqdm\n","import json\n","import os\n","\n","# Seq2Seq 모델 정의\n","class Seq2SeqModel(nn.Module):\n","    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_layers=2, dropout=0.1):\n","        super(Seq2SeqModel, self).__init__()\n","        self.encoder = nn.LSTM(d_model, d_model, num_layers, dropout=dropout, batch_first=True)\n","        self.decoder = nn.LSTM(d_model, d_model, num_layers, dropout=dropout, batch_first=True)\n","        self.src_tok_emb = nn.Embedding(src_vocab_size, d_model)\n","        self.tgt_tok_emb = nn.Embedding(tgt_vocab_size, d_model)\n","        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src, tgt):\n","        src_emb = self.dropout(self.src_tok_emb(src))\n","        tgt_emb = self.dropout(self.tgt_tok_emb(tgt))\n","        _, (hidden, cell) = self.encoder(src_emb)\n","        output, _ = self.decoder(tgt_emb, (hidden, cell))\n","        return self.fc_out(output)\n","\n","# KonlpyTokenizer 클래스 정의\n","class KonlpyTokenizer:\n","    def __init__(self):\n","        self.okt = Okt()\n","        self.word2idx = {}\n","        self.idx2word = {}\n","        self.vocab_size = 0\n","\n","    def fit(self, sentences):\n","        word_set = set(word for sentence in sentences for word in self.okt.morphs(sentence))\n","        self.word2idx = {word: idx+2 for idx, word in enumerate(word_set)}  # 2부터 시작\n","        self.word2idx['<pad>'] = 0\n","        self.word2idx['<unk>'] = 1\n","        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n","        self.vocab_size = len(self.word2idx)\n","\n","    def encode(self, sentence):\n","        return [self.word2idx.get(word, self.word2idx['<unk>']) for word in self.okt.morphs(sentence)]\n","\n","    def decode(self, tokens):\n","        return ' '.join([self.idx2word[token] for token in tokens if token != 0])\n","\n","    def save(self, file_path):\n","        with open(file_path, 'w', encoding='utf-8') as f:\n","            json.dump({'word2idx': self.word2idx, 'idx2word': self.idx2word}, f, ensure_ascii=False, indent=4)\n","\n","    def load(self, file_path):\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            data = json.load(f)\n","            self.word2idx = data['word2idx']\n","            self.idx2word = {int(k): v for k, v in data['idx2word'].items()}\n","            self.vocab_size = len(self.word2idx)"]},{"cell_type":"code","source":["import os\n","\n","# 데이터 준비\n","def read_text_file(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        content = file.readlines()\n","    return [line.strip() for line in content]\n","\n","# 파일 경로 설정 및 데이터 읽기\n","directory_path = '/content/drive/MyDrive/구름/Week4/archive'\n","file_names = ['je.train', 'ko.train', 'je.dev', 'ko.dev']\n","variable_names = ['je_train', 'ko_train', 'je_dev', 'ko_dev']\n","\n","for file_name, variable_name in zip(file_names, variable_names):\n","    file_path = os.path.join(directory_path, file_name)\n","    content = read_text_file(file_path)\n","    globals()[variable_name] = content\n","\n","# 학습 데이터를 일부만 사용\n","je_train = je_train[0:10000]\n","ko_train = ko_train[0:10000]\n","\n","# 문장에 태그 추가\n","tagged_ko_train = [\"<2je> \" + sentence for sentence in ko_train]\n","tagged_je_train = [\"<2ko> \" + sentence for sentence in je_train]\n","\n","tagged_ko_test = [\"<2je> \" + sentence for sentence in ko_dev]\n","tagged_je_test = [\"<2ko> \" + sentence for sentence in je_dev]\n","\n","# 학습 및 테스트 데이터 설정\n","train_src_texts = tagged_ko_train + tagged_je_train\n","train_tgt_texts = je_train + ko_train\n","\n","test_src_texts = tagged_ko_test + tagged_je_test\n","test_tgt_texts = je_dev + ko_dev\n","\n","# 토크나이저 학습\n","tokenizer = KonlpyTokenizer()\n","tokenizer.fit(train_src_texts + train_tgt_texts)"],"metadata":{"id":"Tq1Hbs7l7wUE","executionInfo":{"status":"ok","timestamp":1720284510719,"user_tz":-540,"elapsed":47557,"user":{"displayName":"유인","userId":"09840046609030674956"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 정의\n","class TranslationDataset(Dataset):\n","    def __init__(self, src_texts, tgt_texts, tokenizer, max_length=128):\n","        self.src_texts = src_texts\n","        self.tgt_texts = tgt_texts\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.src_texts)\n","\n","    def __getitem__(self, idx):\n","        src_text = self.src_texts[idx]\n","        tgt_text = self.tgt_texts[idx]\n","        src_ids = self.tokenizer.encode(src_text)[:self.max_length]\n","        tgt_ids = self.tokenizer.encode(tgt_text)[:self.max_length]\n","        src_ids = src_ids + [0] * (self.max_length - len(src_ids))\n","        tgt_ids = tgt_ids + [0] * (self.max_length - len(tgt_ids))\n","        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n","\n","# 데이터 로더 설정\n","train_dataset = TranslationDataset(train_src_texts, train_tgt_texts, tokenizer)\n","test_dataset = TranslationDataset(test_src_texts, test_tgt_texts, tokenizer)\n","\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n","test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=8)\n","\n","src_vocab_size = tokenizer.vocab_size\n","tgt_vocab_size = tokenizer.vocab_size\n","\n","# 모델 정의\n","model_ko_to_je = Seq2SeqModel(src_vocab_size, tgt_vocab_size)\n","model_je_to_ko = Seq2SeqModel(tgt_vocab_size, src_vocab_size)\n","\n","# 훈련 설정\n","optimizer_ko_to_je = Adam(model_ko_to_je.parameters(), lr=5e-5)\n","optimizer_je_to_ko = Adam(model_je_to_ko.parameters(), lr=5e-5)\n","num_epochs = 20\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model_ko_to_je.to(device)\n","model_je_to_ko.to(device)\n","\n","# Early stopping 설정\n","patience = 2\n","best_loss_ko_to_je = float('inf')\n","best_loss_je_to_ko = float('inf')\n","trigger_times_ko_to_je = 0\n","trigger_times_je_to_ko = 0\n","\n","# 검증 함수 정의\n","def validate(model, dataloader, criterion):\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for src, tgt in dataloader:\n","            src, tgt = src.to(device), tgt.to(device)\n","            tgt_input = tgt[:, :-1]\n","            tgt_output = tgt[:, 1:]\n","            output = model(src, tgt_input)\n","            loss = criterion(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n","            val_loss += loss.item()\n","    return val_loss / len(dataloader)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# 모델 훈련\n","progress_bar = tqdm(range(num_epochs * len(train_dataloader)))\n","train_losses_ko_to_je = []\n","train_losses_je_to_ko = []\n","\n","for epoch in range(num_epochs):\n","    model_ko_to_je.train()\n","    model_je_to_ko.train()\n","    epoch_loss_ko_to_je = 0\n","    epoch_loss_je_to_ko = 0\n","    for src, tgt in train_dataloader:\n","        # ko_to_je 훈련\n","        src, tgt = src.to(device), tgt.to(device)\n","        tgt_input = tgt[:, :-1]\n","        tgt_output = tgt[:, 1:]\n","        optimizer_ko_to_je.zero_grad()\n","        output = model_ko_to_je(src, tgt_input)\n","        loss = criterion(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n","        loss.backward()\n","        optimizer_ko_to_je.step()\n","        epoch_loss_ko_to_je += loss.item()\n","\n","        # je_to_ko 훈련\n","        tgt, src = tgt.to(device), src.to(device)  # 소스와 타겟을 바꿔서 훈련\n","        tgt_input = tgt[:, :-1]\n","        tgt_output = tgt[:, 1:]\n","        optimizer_je_to_ko.zero_grad()\n","        output = model_je_to_ko(src, tgt_input)\n","        loss = criterion(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n","        loss.backward()\n","        optimizer_je_to_ko.step()\n","        epoch_loss_je_to_ko += loss.item()\n","\n","        progress_bar.update(1)\n","\n","    avg_epoch_loss_ko_to_je = epoch_loss_ko_to_je / len(train_dataloader)\n","    avg_epoch_loss_je_to_ko = epoch_loss_je_to_ko / len(train_dataloader)\n","    train_losses_ko_to_je.append(avg_epoch_loss_ko_to_je)\n","    train_losses_je_to_ko.append(avg_epoch_loss_je_to_ko)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], ko_to_je Loss: {avg_epoch_loss_ko_to_je}, je_to_ko Loss: {avg_epoch_loss_je_to_ko}\")\n","\n","    val_loss_ko_to_je = validate(model_ko_to_je, test_dataloader, criterion)\n","    val_loss_je_to_ko = validate(model_je_to_ko, test_dataloader, criterion)\n","    print(f\"Validation Loss ko_to_je: {val_loss_ko_to_je}, je_to_ko: {val_loss_je_to_ko}\")\n","\n","    if val_loss_ko_to_je < best_loss_ko_to_je:\n","        best_loss_ko_to_je = val_loss_ko_to_je\n","        trigger_times_ko_to_je = 0\n","        # 모델 저장\n","        torch.save(model_ko_to_je.state_dict(), '/content/drive/MyDrive/transformer_translation_model_ko_to_je.pth')\n","    else:\n","        trigger_times_ko_to_je += 1\n","        if trigger_times_ko_to_je >= patience:\n","            print(\"Early stopping triggered for ko_to_je\")\n","            break\n","\n","    if val_loss_je_to_ko < best_loss_je_to_ko:\n","        best_loss_je_to_ko = val_loss_je_to_ko\n","        trigger_times_je_to_ko = 0\n","        # 모델 저장\n","        torch.save(model_je_to_ko.state_dict(), '/content/drive/MyDrive/transformer_translation_model_je_to_ko.pth')\n","    else:\n","        trigger_times_je_to_ko += 1\n","        if trigger_times_je_to_ko >= patience:\n","            print(\"Early stopping triggered for je_to_ko\")\n","            break\n","\n","# 모델 및 토크나이저 저장\n","tokenizer.save('/content/drive/MyDrive/tokenizer.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":660,"referenced_widgets":["84a2c1e08a4944b7a7359b14a2c49378","7232354dd62144d882cef70165a8fca6","883a29f7dc8349b7b5d82c3f8d263f0f","0b4ff8cad8694b169a780b5174a0bcbe","979a3f26c23542f9af5fe2b598cacb0e","7c17ebd05cf7493b9ba03b0fb485cb8e","f61a24437a3a40dfb6cedec962fdb225","bc1978e415c64555a8238a2f57f9b5bf","66d1113ff9c7463c9e43710fe3c8aa13","6fea253f4f71464e8c639083a007d137","e1e76ab156eb409dac6c3509cec7f10d"]},"id":"09_EUBPr76Nb","executionInfo":{"status":"ok","timestamp":1720293269854,"user_tz":-540,"elapsed":8745941,"user":{"displayName":"유인","userId":"09840046609030674956"}},"outputId":"d35fd6f8-469c-4dbd-c376-d2daeee64a10"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84a2c1e08a4944b7a7359b14a2c49378"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], ko_to_je Loss: 0.6383936259239912, je_to_ko Loss: 0.6447704630792142\n","Validation Loss ko_to_je: 0.8583626879930496, je_to_ko: 0.8582002779960632\n","Epoch [2/20], ko_to_je Loss: 0.49188225446045397, je_to_ko Loss: 0.4942382970750332\n","Validation Loss ko_to_je: 0.8437200621366501, je_to_ko: 0.8432101244211196\n","Epoch [3/20], ko_to_je Loss: 0.47635041212923823, je_to_ko Loss: 0.47644041297510265\n","Validation Loss ko_to_je: 0.836827794599533, je_to_ko: 0.8349805600404739\n","Epoch [4/20], ko_to_je Loss: 0.4611087682157755, je_to_ko Loss: 0.46122181408405305\n","Validation Loss ko_to_je: 0.8245039383888244, je_to_ko: 0.8244213079214096\n","Epoch [5/20], ko_to_je Loss: 0.445674948105216, je_to_ko Loss: 0.44554142490923404\n","Validation Loss ko_to_je: 0.8138091276884079, je_to_ko: 0.8146917772054673\n","Epoch [6/20], ko_to_je Loss: 0.4308459319755435, je_to_ko Loss: 0.4307683040589094\n","Validation Loss ko_to_je: 0.8047707894325257, je_to_ko: 0.8023029254674912\n","Epoch [7/20], ko_to_je Loss: 0.418573568482697, je_to_ko Loss: 0.4174435987502336\n","Validation Loss ko_to_je: 0.8005793831586838, je_to_ko: 0.7955773833990097\n","Epoch [8/20], ko_to_je Loss: 0.40705432519391177, je_to_ko Loss: 0.4049841002073139\n","Validation Loss ko_to_je: 0.7921333383083343, je_to_ko: 0.7876279940366745\n","Epoch [9/20], ko_to_je Loss: 0.39562828962951896, je_to_ko Loss: 0.3932268495567143\n","Validation Loss ko_to_je: 0.7871008230447769, je_to_ko: 0.7821571838378907\n","Epoch [10/20], ko_to_je Loss: 0.3846956463173032, je_to_ko Loss: 0.382042543952167\n","Validation Loss ko_to_je: 0.7815698571681976, je_to_ko: 0.7781191968679428\n","Epoch [11/20], ko_to_je Loss: 0.37432993081472815, je_to_ko Loss: 0.3711388456430286\n","Validation Loss ko_to_je: 0.7797733649730683, je_to_ko: 0.7773083904981614\n","Epoch [12/20], ko_to_je Loss: 0.36431297885626557, je_to_ko Loss: 0.3606609195291996\n","Validation Loss ko_to_je: 0.7789401237726211, je_to_ko: 0.7738001031398773\n","Epoch [13/20], ko_to_je Loss: 0.3543770928785205, je_to_ko Loss: 0.35008029153645037\n","Validation Loss ko_to_je: 0.7791386732578277, je_to_ko: 0.7762145529270172\n","Epoch [14/20], ko_to_je Loss: 0.34468176160007713, je_to_ko Loss: 0.3396956333123147\n","Validation Loss ko_to_je: 0.7766288665533065, je_to_ko: 0.7731683210611343\n","Epoch [15/20], ko_to_je Loss: 0.3349249051399529, je_to_ko Loss: 0.32935179788023233\n","Validation Loss ko_to_je: 0.7807438750505448, je_to_ko: 0.7780393486499786\n","Epoch [16/20], ko_to_je Loss: 0.32560273741558193, je_to_ko Loss: 0.3192660762362182\n","Validation Loss ko_to_je: 0.7837478260278702, je_to_ko: 0.7772222432136535\n","Early stopping triggered for ko_to_je\n"]}]}]}